{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZXoRRoPuiElRn0Y73Ilxh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-ZZRz5AB56t",
        "outputId": "490b5b62-e4d7-4fd0-a3e4-5eb62f97b44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/HRTF_Interpolation_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCHCr2BsCGMl",
        "outputId": "e19d8cfa-55de-4070-c46d-5b4780f06634"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HRTF_Interpolation_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sofa scipy torch matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Du1YmecTCKpD",
        "outputId": "21ea33e3-0a0e-453c-c17e-223d99964f8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sofa\n",
            "  Downloading sofa-0.7.6.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting pyramid (from sofa)\n",
            "  Downloading pyramid-2.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.11/dist-packages (from sofa) (2.0.40)\n",
            "Collecting transaction (from sofa)\n",
            "  Downloading transaction-5.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting validate_email (from sofa)\n",
            "  Downloading validate_email-1.3.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyDNS (from sofa)\n",
            "  Downloading pydns-2.3.6.tar.gz (28 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-sofa\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXif22fVDIlL",
        "outputId": "9da544fd-cacd-44bb-d7b7-d7f4c2ce5889"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-sofa\n",
            "  Downloading python_sofa-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-sofa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from python-sofa) (1.14.1)\n",
            "Collecting netcdf4 (from python-sofa)\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting datetime (from python-sofa)\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting zope.interface (from datetime->python-sofa)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from datetime->python-sofa) (2025.2)\n",
            "Collecting cftime (from netcdf4->python-sofa)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netcdf4->python-sofa) (2025.1.31)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface->datetime->python-sofa) (75.2.0)\n",
            "Downloading python_sofa-0.2.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, cftime, netcdf4, datetime, python-sofa\n",
            "Successfully installed cftime-1.6.4.post1 datetime-5.5 netcdf4-1.7.2 python-sofa-0.2.0 zope.interface-7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET.PY"
      ],
      "metadata": {
        "id": "wlCQUQB_CYH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import sofa\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from scipy.special import sph_harm\n",
        "\n",
        "# --- CONFIG ---\n",
        "SH_ORDER = 16\n",
        "NUM_COEFF = (SH_ORDER + 1) ** 2\n",
        "FREQ_RANGE = (172, 16000)\n",
        "N_KNOWN = 120\n",
        "N_TOTAL = 480\n",
        "N_FREQS = 93\n",
        "\n",
        "# --- HELPERS ---\n",
        "\n",
        "def real_spherical_harmonics(N, theta, phi):\n",
        "    P = len(theta)\n",
        "    C = (N + 1) ** 2\n",
        "    Y = np.zeros((P, C))\n",
        "    idx = 0\n",
        "    for n in range(N + 1):\n",
        "        for m in range(-n, n + 1):\n",
        "            Ynm = sph_harm(m, n, phi, theta)\n",
        "            if m < 0:\n",
        "                Y[:, idx] = np.sqrt(2) * (-1)**m * Ynm.imag\n",
        "            elif m == 0:\n",
        "                Y[:, idx] = Ynm.real\n",
        "            else:\n",
        "                Y[:, idx] = np.sqrt(2) * (-1)**m * Ynm.real\n",
        "            idx += 1\n",
        "    return Y\n",
        "\n",
        "def compute_area_weights(Y_known):\n",
        "    return np.ones(Y_known.shape[0]) / Y_known.shape[0]\n",
        "\n",
        "def process_sofa_file(file_path):\n",
        "    db = sofa.Database.open(file_path)\n",
        "    ir = db.Data.IR.get_values()  # (M, R, N)\n",
        "    fs = db.Data.SamplingRate.get_values(indices={\"M\": 0})\n",
        "\n",
        "    # Get source positions (azimuth, elevation) in radians\n",
        "    pos = db.Source.Position.get_values(system=\"spherical\")[:, :2]\n",
        "    azimuth = np.deg2rad(pos[:, 0])\n",
        "    elevation = np.pi/2 - np.deg2rad(pos[:, 1])\n",
        "\n",
        "    # SH basis matrix for all 480 directions\n",
        "    Y = real_spherical_harmonics(SH_ORDER, elevation, azimuth)\n",
        "\n",
        "    # Extract magnitude HRTFs from HRIRs\n",
        "    n_measurements, n_receivers, n_samples = ir.shape\n",
        "    freqs = rfftfreq(n_samples, d=1/fs)\n",
        "    valid_idx = np.where((freqs >= FREQ_RANGE[0]) & (freqs <= FREQ_RANGE[1]))[0]\n",
        "\n",
        "    HRTF_mag = np.zeros((n_measurements, n_receivers, len(valid_idx)))\n",
        "    for m in range(n_measurements):\n",
        "        for r in range(n_receivers):\n",
        "            hrir = ir[m, r, :]\n",
        "            hrtf = np.abs(rfft(hrir))[valid_idx]\n",
        "            HRTF_mag[m, r, :] = 20 * np.log10(hrtf + 1e-8)\n",
        "\n",
        "    return HRTF_mag, Y\n",
        "\n",
        "# --- MAIN DATASET CLASS ---\n",
        "\n",
        "class HRTFDataset(Dataset):\n",
        "    def __init__(self, sofa_dir, known_idx_path=\"known_directions_idx.npy\"):\n",
        "        self.file_paths = [os.path.join(sofa_dir, f) for f in os.listdir(sofa_dir)\n",
        "                           if f.endswith(\".sofa\") and \"measured\" in f]\n",
        "\n",
        "        if os.path.exists(known_idx_path):\n",
        "            self.known_idx = np.load(known_idx_path)\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Missing known_directions_idx.npy\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        hrtf_mag, Y = process_sofa_file(file_path)\n",
        "\n",
        "        # Left ear\n",
        "        x = hrtf_mag[self.known_idx, 0, :].T  # [93, 120]\n",
        "        y = hrtf_mag[:, 0, :].T               # [93, 480]\n",
        "\n",
        "        Y_known = Y[self.known_idx, :]       # [120, 289]\n",
        "        Y_inv = np.linalg.pinv(Y_known)      # [289, 120]\n",
        "        area = compute_area_weights(Y_known) # [120]\n",
        "\n",
        "        return {\n",
        "            \"x\": torch.tensor(x, dtype=torch.float32),\n",
        "            \"y\": torch.tensor(y, dtype=torch.float32),\n",
        "            \"Y_inv\": torch.tensor(Y_inv.T[:, :81], dtype=torch.float32),  # L=8 for first SHT\n",
        "            \"area\": torch.tensor(area, dtype=torch.float32),\n",
        "            \"Y\": torch.tensor(Y, dtype=torch.float32)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "hSCJHs_XCbQs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "120 known_directions (once)"
      ],
      "metadata": {
        "id": "gDHo6L1sCg4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sofa\n",
        "import os\n",
        "\n",
        "path = \"HRIRs/pp1_HRIRs_measured.sofa\"\n",
        "db = sofa.Database.open(path)\n",
        "\n",
        "n_dirs = db.Dimensions.M  # should be 440\n",
        "np.random.seed(42)\n",
        "known_idx = np.sort(np.random.choice(n_dirs, 120, replace=False))\n",
        "np.save(\"known_directions_idx.npy\", known_idx)\n",
        "\n",
        "print(\"Saved known_directions_idx.npy with shape:\", known_idx.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbN_SDNlClCs",
        "outputId": "7e802719-4ece-4f48-9a5d-2f9896f43e03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved known_directions_idx.npy with shape: (120,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL.PY"
      ],
      "metadata": {
        "id": "JykqeWG0Cby7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math  # also needed for stdv in SHConv\n",
        "\n",
        "# layers\n",
        "\n",
        "class SHT(nn.Module):\n",
        "    def __init__(self, L, Y_inv, area):\n",
        "        \"\"\"\n",
        "        Input shape  : [batch, n_ch, 120]\n",
        "        Output shape : [batch, n_ch, (8+1)**2]\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.Y_inv = Y_inv[:, : (L + 1) ** 2]\n",
        "        self.area = area\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.mul(self.area, x)\n",
        "        x = torch.matmul(x, self.Y_inv)\n",
        "\n",
        "        return x\n",
        "\n",
        "class SHConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, L):\n",
        "        \"\"\"\n",
        "        Input shape  : [batch, in_ch, (L+1)**2]\n",
        "        Output shape : [batch, out_ch, (L+1)**2]\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        ncpt = L + 1\n",
        "\n",
        "        self.weight = nn.Parameter(torch.empty(in_ch, out_ch, ncpt))\n",
        "        self.repeats = nn.Parameter(torch.tensor([(2 * l + 1) for l in range(L + 1)]), requires_grad=False)\n",
        "\n",
        "        stdv = 1.0 / math.sqrt(in_ch * (L + 1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        w = torch.repeat_interleave(self.weight, self.repeats, dim=2)\n",
        "        x = torch.mul(w.unsqueeze(0), x.unsqueeze(2)).sum(1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ISHT1(nn.Module):\n",
        "    def __init__(self, Y):\n",
        "        \"\"\"\n",
        "        Input shape  : [batch, n_ch, (L+1)**2]\n",
        "        Output shape : [batch, n_ch, 120]\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.Y = Y\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.matmul(x, self.Y[: x.shape[-1], :])\n",
        "\n",
        "        return x\n",
        "\n",
        "class ISHT2(nn.Module):\n",
        "    def __init__(self, Y480_289):\n",
        "        \"\"\"\n",
        "        Input shape  : [batch, n_ch, (L+1)**2]\n",
        "        Output shape : [batch, n_ch, 480]\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.Y480_289 = Y480_289\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.matmul(x, self.Y480_289)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# model\n",
        "\n",
        "class SCNN(nn.Module):\n",
        "    def __init__(self, Y, Y_inv, area,Y480_289, in_ch, out_ch, L,nonlinear=None, fullband=True, bn=True):\n",
        "        \"\"\"\n",
        "        In channel shape  : [batch, in_ch, n_vertex]\n",
        "        Out channel shape : [batch, out_ch, n_vertex]\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.first = nn.Sequential(SHT(8, Y_inv, area),ISHT1(Y))\n",
        "        self.shconv1 = nn.Sequential(SHT(L, Y_inv, area), SHConv(in_ch, 93*2, L), ISHT1(Y))\n",
        "        self.shconv2 = nn.Sequential(SHT(16, Y_inv, area), SHConv(93*2, out_ch, 16), ISHT1(Y))\n",
        "        self.final = nn.Sequential(SHT(16, Y_inv, area),ISHT2(Y480_289))\n",
        "\n",
        "        self.impulse1 = nn.Conv1d(in_ch, 93*2, kernel_size=1, stride=1, bias=not bn) if fullband else lambda _: 0\n",
        "        self.impulse2 = nn.Conv1d(93*2, in_ch, kernel_size=1, stride=1, bias=not bn) if fullband else lambda _: 0\n",
        "        self.nonlinear = F.relu if nonlinear is not None else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first(x)\n",
        "\n",
        "        x = self.shconv1(x) + self.impulse1(x)\n",
        "        x = self.nonlinear(x)\n",
        "\n",
        "        x = self.shconv2(x) + self.impulse2(x)\n",
        "        x = self.nonlinear(x)\n",
        "\n",
        "        x = self.final(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "kmUGK0_KCdkz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN.PY"
      ],
      "metadata": {
        "id": "t6x9sdrSCeH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "# from dataset import HRTFDataset\n",
        "# from model import SCNN\n",
        "import os\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-3\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SH_ORDER = 16\n",
        "\n",
        "# --- LSD LOSS FUNCTION ---\n",
        "def lsd_loss(y_pred, y_true):\n",
        "    return torch.sqrt(torch.mean((y_pred - y_true) ** 2))\n",
        "\n",
        "# --- Load dataset ---\n",
        "dataset = HRTFDataset(sofa_dir=\"HRIRs\", known_idx_path=\"known_directions_idx.npy\")\n",
        "dataset.file_paths = dataset.file_paths[:10]  # Limit to first 10 files for quick test\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# --- Sample a batch to get input/output shapes ---\n",
        "sample = next(iter(loader))\n",
        "in_ch = sample[\"x\"].shape[1]      # 93 frequency bins\n",
        "out_ch = sample[\"y\"].shape[1]\n",
        "\n",
        "# --- Init model ---\n",
        "model = SCNN(\n",
        "    Y=sample[\"Y\"].to(DEVICE),\n",
        "    Y_inv=sample[\"Y_inv\"].to(DEVICE),\n",
        "    area=sample[\"area\"].to(DEVICE),\n",
        "    Y480_289=sample[\"Y\"].to(DEVICE),\n",
        "    in_ch=in_ch,\n",
        "    out_ch=out_ch,\n",
        "    L=SH_ORDER,\n",
        "    nonlinear=True\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# --- Training loop ---\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"x\"].to(DEVICE)               # [B, 93, 120]\n",
        "        y = batch[\"y\"].to(DEVICE)               # [B, 93, 480]\n",
        "        model.Y_inv = batch[\"Y_inv\"].to(DEVICE) # dynamically assign if needed\n",
        "        model.area = batch[\"area\"].to(DEVICE)\n",
        "        model.Y = batch[\"Y\"].to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)                       # → [B, 93, 480]\n",
        "        loss = lsd_loss(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | LSD Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# --- Save the model ---\n",
        "torch.save(model.state_dict(), \"scnn_model_test10.pth\")\n",
        "print(\"✅ Model saved as scnn_model_test10.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "N5WagfsXCfsU",
        "outputId": "f7d7c353-88c9-4218-97f0-7caeb2eefc38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected size for first two dimensions of batch2 tensor to be: [1, 120] but got: [1, 81].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9a09fe5b77e6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# → [B, 93, 480]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-92a5768455c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpulse1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-92a5768455c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [1, 120] but got: [1, 81]."
          ]
        }
      ]
    }
  ]
}